{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "regression_exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ai161/hello-world/blob/main/regression_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1teYqNYHYGz"
      },
      "source": [
        "# 確認問題"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNwg0BOzHYG4"
      },
      "source": [
        "## 1. 単回帰"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBMfMUFnHYG4"
      },
      "source": [
        "以下のデータ$\\mathcal{D}_s$に対して単回帰分析を行うプログラムを実装せよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQU3cx9DHYG5"
      },
      "source": [
        "D = np.array([[1, 3], [3, 6], [6, 5], [8, 7]])\n",
        "X = D[:,0]\n",
        "Y = D[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryR0X1I0HYG5"
      },
      "source": [
        "なお，NumPy, SciPy, scikit-learnには回帰分析を行う便利な関数として以下のようなものがあるが，ここでは使わずに講義中で説明した式をプログラムとして表現すること．\n",
        "\n",
        "+ [np.polyfit](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html), [np.polynomial.polynomial.Polynomial.fit](https://numpy.org/doc/stable/reference/generated/numpy.polynomial.polynomial.Polynomial.fit.html#numpy.polynomial.polynomial.Polynomial.fit)\n",
        "+ [scipy.linalg.lstsq](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lstsq.html), [scipy.optimize.curve_fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html), [scipy.stats.linregress](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html)\n",
        "+ [sklearn.linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPZTw2oVHYG5"
      },
      "source": [
        "### 1. (1) 単回帰の実装\n",
        "\n",
        "$\\mathcal{D}_s$に対して単回帰を行い，回帰直線の係数$a$と$b$の値を求めよ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iolrcSDHYG6"
      },
      "source": [
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDfZy9DJHYG6"
      },
      "source": [
        "### 1. (2) 回帰直線の描画\n",
        "\n",
        "単回帰で求めた回帰直線をデータ点とともにグラフに描け"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHFh1hOWHYG6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w2EhXPAHYG6"
      },
      "source": [
        "### 1. (3) 残差の計算\n",
        "\n",
        "各事例$(x_i, y_i)$に対して残差$\\hat{\\epsilon}_i$を求めよ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOekf52ZHYG7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8M6cA80HYG7"
      },
      "source": [
        "### 1. (4) 説明変数と残差の共分散\n",
        "\n",
        "説明変数と残差の共分散を求めよ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HEbMsPCHYG7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbbQu0A4HYG7"
      },
      "source": [
        "### 1. (5) 目的変数の推定値と残差の共分散\n",
        "\n",
        "目的変数の推定値と残差の共分散を求めよ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPf5tgKLHYG7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voJ4gR3kHYG7"
      },
      "source": [
        "### 1. (6) 決定係数\n",
        "\n",
        "決定係数（$R^2$）を求めよ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7_K9VJnHYG8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgew5N8CHYG8"
      },
      "source": [
        "## 2. 重回帰"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqHBx1KlHYG8"
      },
      "source": [
        "データ$\\mathcal{D}_s$に対して多項式のフィッティングを行いたい．以下の処理を行うプログラムを作成せよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mhm7DRftHYG8"
      },
      "source": [
        "D = np.array([[1, 3], [3, 6], [6, 5], [8, 7]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy3dj_YTHYG8"
      },
      "source": [
        "なお，NumPy, SciPy, scikit-learnには回帰分析を行う便利な関数として以下のようなものがあるが，ここでは使わずに講義中で説明した式をプログラムとして表現すること．\n",
        "\n",
        "+ [np.polyfit](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html), [np.polynomial.polynomial.Polynomial.fit](https://numpy.org/doc/stable/reference/generated/numpy.polynomial.polynomial.Polynomial.fit.html#numpy.polynomial.polynomial.Polynomial.fit)\n",
        "+ [scipy.linalg.lstsq](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lstsq.html), [scipy.optimize.curve_fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html), [scipy.stats.linregress](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html)\n",
        "+ [sklearn.linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1DQGyNdHYG8"
      },
      "source": [
        "### 2. (1) ２次関数による重回帰\n",
        "\n",
        "$y = w_0 + w_1 x + w_2 x^2$とおき，重回帰により平均二乗残差を最小にする$\\pmb{w} = \\begin{pmatrix}\n",
        "w_0 \\\\\n",
        "w_1 \\\\\n",
        "w_2\n",
        "\\end{pmatrix}$を求めよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKOpdzymHYG9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHwNjW96HYG9"
      },
      "source": [
        "### 2. (2) 回帰曲線の描画\n",
        "\n",
        "回帰で求めた2次関数をデータ点とともにグラフに描け．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOCj-1X0HYG9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIpCGaVrHYG9"
      },
      "source": [
        "### 2. (3) 決定係数\n",
        "\n",
        "回帰で得られた2次関数の決定係数（$R^2$）を求めよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMv7Cl3DHYG9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_IA7SQgHYG9"
      },
      "source": [
        "### 2. (4) 3次関数による重回帰\n",
        "\n",
        "$y = w_0 + w_1 x + w_2 x^2 + w_3 x^3$とおき，重回帰により平均二乗残差を最小にする$\\pmb{w} = \\begin{pmatrix}\n",
        "w_0 \\\\\n",
        "w_1 \\\\\n",
        "w_2 \\\\\n",
        "w_3\n",
        "\\end{pmatrix}$を求めよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKYnMi8HHYG9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWuq0rQnHYG-"
      },
      "source": [
        "### 2. (5) 回帰曲線の描画\n",
        "\n",
        "回帰で求めた3次関数をデータ点とともにグラフに描け"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwqgq_39HYG-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vxr5liLUHYG-"
      },
      "source": [
        "### 2. (6) 決定係数\n",
        "\n",
        "回帰で求めた3次関数の決定係数（$R^2$）を求めよ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNe1OUs2HYG-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3B-So8YHYG-"
      },
      "source": [
        "## 3. モデル選択と正則化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDYv3-SNHYG-"
      },
      "source": [
        "### 3. (1) 9次関数によるリッジ回帰\n",
        "\n",
        "例として用いてきた以下の学習データ`X`, `Y`に対してリッジ回帰を行い，回帰曲線をプロットせよ．\n",
        "ただし，正則化のハイパーパラメータは$\\alpha = 10^{-9}, 10^{-6}, 10^{-3}, 1$の4通りを試し，すべての回帰曲線と学習データの各点を一つのグラフ上にプロットせよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0ClOTweHYG-"
      },
      "source": [
        "X = np.array([ 0.  ,  0.11,  0.25,  0.29,  0.41,  0.42,  0.43,  0.8 ,  0.81, 1.  ])\n",
        "Y = np.array([ 0.04,  0.75,  1.  ,  0.99,  0.31,  0.52,  0.38, -0.99, -1.05, 0.  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj1JPQNQHYG-"
      },
      "source": [
        "なお，scikit-learnにはリッジ回帰を行う便利なクラス[sklearn.linear_model.Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)があるが，ここでは使わずに講義中で説明した式をプログラムとして表現すること．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY2wIX1LHYG_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaZ8_9WpHYG_"
      },
      "source": [
        "### 3. (2) パラメータの$L_2$ノルム"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGcZtPhvHYG_"
      },
      "source": [
        "学習した4つのモデルのパラメータの$L_2$ノルムを計算し，表示せよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG2BVzStHYG_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFcXe3YHHYG_"
      },
      "source": [
        "### 3. (3) 検証データに基づく$\\alpha$の選択"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVsfVtWcHYG_"
      },
      "source": [
        "例として用いてきた以下の検証データ`X_valid`, `Y_valid`に対して，これまでに学習した4つのモデルの平均二乗残差（MSR）を計算し，正則化のハイパーパラメータとして最も汎化性能が高いと考えられるものがどれか，報告せよ．計算結果を示した上で「○○なので$\\alpha = \\dots$のモデルがよい」と回答すれば十分である．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iRLfz8FHYG_"
      },
      "source": [
        "X_valid = np.array([ 0.05,  0.08,  0.12,  0.16,  0.28,  0.44,  0.47,  0.55,  0.63,  0.99])\n",
        "Y_valid = np.array([ 0.35,  0.58,  0.68,  0.87,  0.83,  0.45,  0.01, -0.36, -0.83, -0.06])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx92Aa6YHYG_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdqFSXYiHYG_"
      },
      "source": [
        "## 4. 勾配法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAmBodK1HYHA"
      },
      "source": [
        "以下のデータ$\\mathcal{D}_s$について，確率的勾配降下法で単回帰を行い，パラメータを推定せよ．ここでも、便利なモジュール等は使わずに、講義中で説明した式・アルゴリズムをプログラムとして表現すること．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68IUZqN9HYHA"
      },
      "source": [
        "D = np.array([[1, 3], [3, 6], [6, 5], [8, 7]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JDCNDw3HYHA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}